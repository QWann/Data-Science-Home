{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This project is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "\n",
    "All data for this assignment has been provided through the [Detroit Open Data Portal](https://data.detroitmi.gov/).\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions** \n",
    "\n",
    "    readonly/train.csv - the training set (all tickets issued 2004-2011)\n",
    "    readonly/test.csv - the test set (all tickets issued 2012-2016)\n",
    "    readonly/addresses.csv & readonly/latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def blight_model():\n",
    "    \n",
    "    dataset_training = pd.read_csv('train.csv', encoding = 'ISO-8859-1')\n",
    "    dataset_testing = pd.read_csv('test.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "    \n",
    "    counts = dataset_training[\"compliance\"].value_counts() # only counts numeric values (i.e will miss N.a.N)\n",
    "    NR_counts = len(dataset_training) - (counts[0] + counts[1])\n",
    "\n",
    "    \n",
    "    #print('The original training data set has shape: {}'.format(np.shape(dataset_training)))\n",
    "    #print('The class distribution is: <{} non responsible>, <{} compliant> and <{} non compliant>'.\\\n",
    "    #      format(NR_counts, counts[1], counts[0]))\n",
    "    #print()\n",
    "    \n",
    "    # We remove tickets that were considered not valid from the training dataset as they are not present in the test set\n",
    "    train_data_f = dataset_training.dropna(subset=['compliance'])\n",
    "    #print('After removing non responsible tickets: {}'.format(np.shape(train_data_f)))\n",
    "    \n",
    "    # We remove entries of people not living in detroit (zip code in detroit are 5 digits integer)\n",
    "    train_data_f['zip_code'] = pd.to_numeric(train_data_f['zip_code'], errors = 'coerce')\n",
    "    train_data_f = train_data_f.dropna(subset=['zip_code'])\n",
    "    train_data_f['zip_code'] = train_data_f['zip_code'].astype(str)\n",
    "    train_data_f = train_data_f[train_data_f['zip_code'].str.len() == 7]\n",
    "    \n",
    "    dataset_testing['zip_code'] = pd.to_numeric(dataset_testing['zip_code'], errors = 'coerce')\n",
    "    #test_data_f = dataset_testing.dropna(subset=['zip_code'])\n",
    "    dataset_testing['zip_code'] = dataset_testing['zip_code'].astype(str)\n",
    "    test_data_f = dataset_testing.copy()\n",
    "    \n",
    "    \n",
    "    # Create list of features we want to use for our classification problem\n",
    "    cat_features = ['disposition', 'zip_code']\n",
    "    num_features = ['fine_amount', 'judgment_amount','discount_amount']\n",
    "    \n",
    "    y_train = train_data_f['compliance'] # we keep the labels in another array\n",
    "\n",
    "    train_data_f = train_data_f[cat_features + num_features]\n",
    "    test_data_f = test_data_f[cat_features + num_features]\n",
    "    \n",
    "    # Now we transform categorical variables 'dispoisiton', 'zip_code', into one hot encoded features\n",
    "    one_hot_encoding = pd.get_dummies(train_data_f[cat_features])\n",
    "    one_hot_encoding[num_features] = train_data_f[num_features]\n",
    "    X_train = one_hot_encoding\n",
    "    \n",
    "    one_hot_encoding_test = pd.get_dummies(test_data_f[cat_features])\n",
    "    print(np.shape(one_hot_encoding_test))\n",
    "    one_hot_encoding_test[num_features] = test_data_f[num_features]\n",
    "    X_test = one_hot_encoding_test\n",
    "    \n",
    "    print('Training dataset shape before alignment: {}'.format(np.shape(X_train)))\n",
    "    print('Testing dataset shape before alignment: {}'.format(np.shape(X_test)))\n",
    "    \n",
    "    X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n",
    "    \n",
    "    print('Training dataset shape after alignment: {}'.format(np.shape(X_train)))\n",
    "    print('Testing dataset shape after alignment: {}'.format(np.shape(X_test)))\n",
    "    \n",
    "    \n",
    "    ####################################################################################################\n",
    "    ## block when optimizing for parameters\n",
    "    \n",
    "    parameters = {'n_estimators': [100,500], 'max_depth':[5,10]}\n",
    "    RF = RandomForestClassifier()\n",
    "    clf_grid_auc = GridSearchCV(RF, parameters, cv = 3)\n",
    "    clf_grid_auc.fit(X_train, y_train)\n",
    "    #print(clf_grid_auc.cv_results_)\n",
    "    \n",
    "    print('Grid best parameters (best AUC): {}'.format(clf_grid_auc.best_params_))\n",
    "    print('Grid best AUC: {}'.format(clf_grid_auc.best_score_))\n",
    "    \n",
    "    probas = clf_grid_auc.predict_proba(X_test)\n",
    "    #####################################################################################################\n",
    "    # Here we know which parameters work best : used for testing or submiting\n",
    "    \n",
    "    #RF = RandomForestClassifier(max_depth=5, n_estimators=100).fit(X_train, y_train)\n",
    "    #predicted = RF.predict_proba(X_train)\n",
    "    #predicted = predicted[:,1] #we only keep prediciton for the positive class\n",
    "\n",
    "    #AUC_score = roc_auc_score(y_train, predicted)\n",
    "    #print('AUC score on training set: {}'.format(AUC_score))\n",
    "    #probas = RF.predict_proba(X_test)\n",
    "    \n",
    "    s = pd.Series(probas[:,1], index = dataset_testing['ticket_id'] )\n",
    "   \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (11,12,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61001, 2786)\n",
      "Training dataset shape before alignment: (158831, 3027)\n",
      "Testing dataset shape before alignment: (61001, 2789)\n",
      "Training dataset shape after alignment: (158831, 1248)\n",
      "Testing dataset shape after alignment: (61001, 1248)\n",
      "[ 0.06394429  0.1206205   0.06089999 ...,  0.06089999  0.1329433   0.0684611 ]\n",
      "AUC score on training set: 0.7949919098514768\n"
     ]
    }
   ],
   "source": [
    "#test = blight_model()\n",
    "#test = blight_model()\n",
    "test = blight_model()\n",
    "#print(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
